```
# 基于 cpu 进行模型推理
https://github.com/abetlen/llama-cpp-python/

# 需要生成ggml格式的bin文件，进行量化

# 两种量化方案
gptq vs ggml

# 量化
https://blog.csdn.net/god_zzZ/article/details/130328307
```

## llama.cpp转换

```
https://github.com/ggerganov/llama.cpp
```

## vLLM 转换

```
vLLM：https://github.com/vllm-project/vllm
https://www.atyun.com/56675.html
```