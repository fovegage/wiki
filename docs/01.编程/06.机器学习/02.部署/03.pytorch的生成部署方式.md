---
title: pytorch的生成部署方式
date: 2023-08-11 09:39:30
permalink: /pages/0126a4/
categories:
  - 编程
  - 机器学习
  - 部署
tags:
  - 
author: 
  name: fovegage
  link: https://github.com/fovegage
---
## 整体步骤

```
# 注意java版本大于17
# /Library/Java/JavaVirtualMachines/jdk-20.jdk/Contents/Home/bin
# 切换java版本：https://juejin.cn/post/6871959224314757134
# /usr/libexec/java_home -V 查看所有版本
export JAVA_HOME=`/usr/libexec/java_home -v 20.0.1`

# 下载仓库
git clone https://github.com/pytorch/serve

# 必须使用该初始化环境 cpu
python ./ts_scripts/install_dependencies.py
python ./ts_scripts/install_dependencies.py --cuda=cu110  # gpu

# 生成protobuf
python -m grpc_tools.protoc --proto_path=frontend/server/src/main/resources/proto/ --python_out=ts_scripts --grpc_python_out=ts_scripts frontend/server/src/main/resources/proto/inference.proto frontend/server/src/main/resources/proto/management.proto

# 将pth打包为mar
torch-model-archiver --model-name densenet161 --version 1.0 --model-file ./examples/image_classifier/densenet_161/model.py --serialized-file ./model_store/densenet161-8d451a50.pth --export-path model_store --extra-files ./examples/image_classifier/index_to_name.json --handler image_classifier

# 启动serve (--models 配置使用的模型)
torchserve --start --ncs --model-store ./model_store --models ./model_store/densenet161.mar

# http 测试
curl http://127.0.0.1:8080/predictions/densenet161 -T kitten_small.jpg

# grpc 测试
python ts_scripts/torchserve_grpc_client.py infer densenet161 examples/image_classifier/kitten.jpg
python ts_scripts/torchserve_grpc_client.py register densenet161
python ts_scripts/torchserve_grpc_client.py unregister densenet161
```

## torch-model-archiver

```
--model-name: 模型名称，导出后的模型文件是“模型名称.mar”
--serialized-file：mar、tgz都可以，模型序列化文件，这里有两种文件数据，一种是eager mode模式下，包含状态字典的.pt或者.pth文件；另一种是TorchScript条件下的可执行模块。
--model-file：模型结构框架，通常只包含一个类，类是torch.nn.modules的子类, 包含 向前转播等
--handler： torchserver 的入口程序，它负责模型的加载，预测等
--extra-files：额外文件，模型运行等其它额外文件都可以，可以包含多个，用逗号将不同文件拼接成一个字符串。
--run-time：选择运行的python版本。
--archive-format：选择压缩文件的格式, {tgz,no-archive,default} 。可以是tgz压缩文件，也可以是mar文件。
--export-path：mar存档文件的保存地址，未设置则保存在当前目录。
-f: 强制覆盖。
-v --version: 模型的版本
-r, --requirement-f: requirements.txt依赖包，模型环境相关的依赖包
```

![](https://obsidian-foveagge.oss-cn-beijing.aliyuncs.com/blog/9RHBwj.png)

## 参考

- [torchserve调用官方库模型](https://blog.csdn.net/weixin_45063703/article/details/125146002)
- [torchserve使用-注册模型设置参数（二）](https://blog.csdn.net/weixin_34910922/article/details/114552407)
- [官方github demo](https://github.com/pytorch/serve/tree/master/examples/Huggingface_Transformers)
- [使用TorchServe部署PyTorch模型以进行大规模推理](https://blog.csdn.net/zhoumoon/article/details/109283826)
- [使用 TorchServe 部署 Model](https://xiang753017.gitbook.io/zixiang-blog/shi-yong-torchserve-bu-shu-model)