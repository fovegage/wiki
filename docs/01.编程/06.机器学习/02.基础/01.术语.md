---
title: 术语
date: 2023-06-08 23:51:46
permalink: /pages/f4e6a2/
categories:
  - 编程
  - 机器学习
  - 基础
tags:
  - 
author: 
  name: fovegage
  link: https://github.com/fovegage
---
### tensorflow
- checkpoint: Checkpoint 只保存模型的参数，不保存模型的计算过程，因此一般用于在具有模型源代码的时候恢复之前训练好的模型参数。如果需要导出模型（无需源代码也能运行模型）。
### pytroch
- batch_size: 每个batch加载多少个样本(默认: 1)
- **num_workers** : 用多少个子进程加载数据。0表示数据将在主进程中加载(默认: 0)
- local_rank: 进程内的 GPU 编号，非显式参数，这个一般由 torch.distributed.launch 内部指定。例如， rank = 3，local_rank = 0 表示第 3 个进程内的第 1 块 GPU
- rank: rank=0为master节点，进程号
- World_size: 进程组中的进程数，可以认为是全局进程个数
- backend: 进程通信库, PyTorch 支持NCCL，GLOO，MPI
- group: 所有进程的子集，用于集体通信等
- checkpoint:  是**一种用时间换显存的技术**，一般训练模式下，pytorch 每次运算后会保留一些中间变量用于求导，而使用checkpoint 的函数，则不会保留中间变量，中间变量会在求导时再计算一次，因此减少了显存占用，跟tensorflow 的checkpoint 是完全不同的东西


![[Pasted image 20230426102344.png]]

### 文档
```
https://www.cnblogs.com/rossiXYZ/p/15546837.html
```