## 原理

```
spark-operator：管理
sprak-driver：调度
node-executor: 具体干活的
```

![](https://obsidian-foveagge.oss-cn-beijing.aliyuncs.com/blog/wLTSrW.png)
![](https://obsidian-foveagge.oss-cn-beijing.aliyuncs.com/blog/sjKawO.png)
![](https://obsidian-foveagge.oss-cn-beijing.aliyuncs.com/blog/5Oz5B4.png)
![](https://obsidian-foveagge.oss-cn-beijing.aliyuncs.com/blog/ubbX4H.png)

## 启动

```
# driver 启动
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0/jre/bin/java -cp /opt/spark/jars/* -Xmx4g org.apache.spark.deploy.SparkSubmit --deploy-mode client --conf spark.driver.bindAddress=xx.xx.xx.xx --properties-file /opt/spark/conf/spark.properties --class org.apache.spark.examples.JavaWordCount local:///opt/spark/examples/target/scala-2.11/jars/spark-examples_2.11-2.4.5.jar oss://{wordcount-file-oss-bucket}/

# spark on k8s 根据下面的配置进行启动
--master k8s://https://10.6.16.32:6443 \
--deploy-mode cluster \
--conf spark.kubernetes.namespace=spark \
--conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
```

## Operator
```
SparkApplication
ScheduledSparkApplication
```

## 参考文档

- [Spark on k8s 的安装和使用-大数据学习系列（六）](https://blog.csdn.net/zhenwudi/article/details/130966742)
- [Spark on Kubernetes作业执行流程](http://fanyilun.me/2021/08/22/Spark%20on%20Kubernetes%E4%BD%9C%E4%B8%9A%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/)